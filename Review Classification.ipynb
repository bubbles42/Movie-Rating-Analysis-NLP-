{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f4685f-6baa-4587-a3de-d4673ee6ff82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2d590a-056a-4ba0-867a-0b07f1b5dc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8650 entries, 0 to 8649\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   review_id       8650 non-null   object \n",
      " 1   movie_id        8650 non-null   int64  \n",
      " 2   imdb_id         8650 non-null   object \n",
      " 3   original_title  8650 non-null   object \n",
      " 4   review          8650 non-null   object \n",
      " 5   rating          7454 non-null   float64\n",
      " 6   target          8650 non-null   object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 473.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64ecc16e83901800af821d50</td>\n",
       "      <td>843</td>\n",
       "      <td>tt0118694</td>\n",
       "      <td>花樣年華</td>\n",
       "      <td>This is a fine piece of cinema from Wong Kar-W...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>exclude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57086ff5c3a3681d29001512</td>\n",
       "      <td>7443</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>A guilty pleasure for me personally, as I love...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>high-rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5bb5ac829251410dcb00810c</td>\n",
       "      <td>7443</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>Made my roommate who hates stop-motion animati...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>exclude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f0c53a013a32000357ec505</td>\n",
       "      <td>7443</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>A very good stop-motion animation!\\r\\n\\r\\n&lt;em&gt;...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>exclude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64ecc027594c9400ffe77c91</td>\n",
       "      <td>7443</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>Ok, there is an huge temptation to riddle this...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>exclude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  review_id  movie_id    imdb_id original_title  \\\n",
       "0  64ecc16e83901800af821d50       843  tt0118694           花樣年華   \n",
       "1  57086ff5c3a3681d29001512      7443  tt0120630    Chicken Run   \n",
       "2  5bb5ac829251410dcb00810c      7443  tt0120630    Chicken Run   \n",
       "3  5f0c53a013a32000357ec505      7443  tt0120630    Chicken Run   \n",
       "4  64ecc027594c9400ffe77c91      7443  tt0120630    Chicken Run   \n",
       "\n",
       "                                              review  rating       target  \n",
       "0  This is a fine piece of cinema from Wong Kar-W...     7.0      exclude  \n",
       "1  A guilty pleasure for me personally, as I love...     9.0  high-rating  \n",
       "2  Made my roommate who hates stop-motion animati...     6.0      exclude  \n",
       "3  A very good stop-motion animation!\\r\\n\\r\\n<em>...     8.0      exclude  \n",
       "4  Ok, there is an huge temptation to riddle this...     7.0      exclude  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = 'Data-NLP/processed_data.joblib'\n",
    "df = joblib.load(fpath)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48cce188-2bd6-4222-8251-f537460747eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop reviews with no raiting\n",
    "df['rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdee684-b69a-4a33-839c-0302d3a1aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38e6751-136e-458b-9e9f-62223d999e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38197588-82a3-47e1-8563-497908066eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']  \n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f92c443-d5f2-4938-9a10-28d04056205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb075a92-1cb1-415c-99bc-407a511918af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and MultinomialNB\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and LogisticRegression\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831b56c8-ce0d-4131-ab63-df8605964612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     exclude       0.68      1.00      0.81      1522\n",
      " high-rating       0.00      0.00      0.00       365\n",
      "  low-rating       1.00      0.01      0.01       350\n",
      "\n",
      "    accuracy                           0.68      2237\n",
      "   macro avg       0.56      0.34      0.27      2237\n",
      "weighted avg       0.62      0.68      0.55      2237\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austi\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\austi\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\austi\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     exclude       0.71      1.00      0.83      1522\n",
      " high-rating       0.83      0.07      0.13       365\n",
      "  low-rating       0.97      0.17      0.29       350\n",
      "\n",
      "    accuracy                           0.72      2237\n",
      "   macro avg       0.84      0.41      0.41      2237\n",
      "weighted avg       0.77      0.72      0.63      2237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the MultinomialNB pipeline on the training data\n",
    "pipeline_nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_nb = pipeline_nb.predict(X_test)\n",
    "\n",
    "# Evaluate the MultinomialNB model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"MultinomialNB Model Performance:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Fit the LogisticRegression pipeline on the training data\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_lr = pipeline_lr.predict(X_test)\n",
    "\n",
    "# Evaluate the LogisticRegression model\n",
    "print(\"LogisticRegression Model Performance:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb0d80-e572-4663-9fd1-cd479f4c6ecd",
   "metadata": {},
   "source": [
    "It appears that the logisitc regression model is performing better than the MultinomialNB Model. Now I will do some gridsearch to try and optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969ce26c-8ae0-4d96-8175-a6936e88c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),  # Start with TfidfVectorizer; can also use CountVectorizer\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Logistic Regression as the classifier\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'vectorizer__stop_words': [None, 'english'],  # None or English stopwords\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],  # Unigrams or Bigrams\n",
    "    'vectorizer__min_df': [1, 2, 5],  # Minimum document frequency\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],  # Maximum document frequency\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996477e2-2029-49d8-92e7-a9f976407898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;vectorizer__max_df&#x27;: [0.9, 0.95, 1.0],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [1, 2, 5],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;vectorizer__max_df&#x27;: [0.9, 0.95, 1.0],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [1, 2, 5],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__min_df': [1, 2, 5],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vectorizer__stop_words': [None, 'english']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1f28f8-9d98-4273-9342-7a60689f807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "{'vectorizer__max_df': 0.9, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': None}\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     exclude       0.74      0.97      0.84      1522\n",
      " high-rating       0.72      0.21      0.33       365\n",
      "  low-rating       0.88      0.29      0.44       350\n",
      "\n",
      "    accuracy                           0.74      2237\n",
      "   macro avg       0.78      0.49      0.54      2237\n",
      "weighted avg       0.76      0.74      0.69      2237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the best parameters\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Predict with the best found model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff233c-6399-4d99-836a-b50978d184c1",
   "metadata": {},
   "source": [
    "The model has an overall accuracy of 74%, which means it correctly predicts the rating category 74% of the time across the test dataset.\r\n",
    "For the \"exclude\" category, the model shows a high precision and recall, leading to an F1-score of 0.84, indicating strong performance in identifying this class.\r\n",
    "The \"high-rating\" and \"low-rating\" categories, however, have lower F1-scores (0.33 and 0.44, respectively), suggesting that the model struggles more with these classifications. The low recall values indicate that the model misses a significant portion of these classes, whereas the precision values suggest the predictions it does make are reasonably reliable (more so for \"low-rating\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa7f960-26a9-4b2e-b7a5-cf1d03e2b3e2",
   "metadata": {},
   "source": [
    "## RNN (NLP Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64d4484c-baec-4165-84da-bb0bc481d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and return encoded labels\n",
    "y_integers = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert the integer encoded labels to one-hot encodings\n",
    "y_onehot = tf.keras.utils.to_categorical(y_integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e001fc-18ed-403a-997b-c5e4bd3e0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, test, and validation sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_onehot, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04949965-ed0b-4004-b1cc-df2bef1a9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TextVectorization layer\n",
    "max_features = 10000  # Size of the vocabulary\n",
    "sequence_length = 250  # Maximum length of the sequence\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "# Fit the TextVectorization layer on the training texts\n",
    "vectorize_layer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "883e7304-d97e-498a-a2d0-21dbc82a3073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10000\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vectorize_layer.get_vocabulary())\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a938836c-01bd-4f87-8f00-b2c4e893c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 250)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 250, 64)           640064    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,283\n",
      "Trainable params: 673,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "model.add(layers.Embedding(input_dim=max_features + 1, output_dim=64, mask_zero=True))\n",
    "model.add(layers.LSTM(64))\n",
    "model.add(layers.Dense(units=y_onehot.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfeaee69-37cf-4d61-b7b0-ae051effa9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "164/164 [==============================] - 23s 123ms/step - loss: 0.8303 - accuracy: 0.6841 - val_loss: 0.7890 - val_accuracy: 0.6932\n",
      "Epoch 2/5\n",
      "164/164 [==============================] - 19s 118ms/step - loss: 0.6218 - accuracy: 0.7418 - val_loss: 0.7385 - val_accuracy: 0.7057\n",
      "Epoch 3/5\n",
      "164/164 [==============================] - 19s 115ms/step - loss: 0.3849 - accuracy: 0.8559 - val_loss: 0.9341 - val_accuracy: 0.6852\n",
      "Epoch 4/5\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.2473 - accuracy: 0.9149 - val_loss: 1.0951 - val_accuracy: 0.6476\n",
      "Epoch 5/5\n",
      "164/164 [==============================] - 18s 111ms/step - loss: 0.1396 - accuracy: 0.9542 - val_loss: 1.1781 - val_accuracy: 0.6413\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd0212d-db7f-4843-8ed8-3db0d8485d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 5s 30ms/step - loss: 0.1173 - accuracy: 0.9665\n",
      "Training Accuracy: 0.9664558172225952\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(train_dataset)\n",
    "print(f\"Training Accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "203d5f5e-954d-471d-8129-13e8e681326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 32ms/step - loss: 1.2265 - accuracy: 0.6005\n",
      "Test Accuracy: 0.6005361676216125\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a3c32-051b-4c8a-b28a-514f36c4a10a",
   "metadata": {},
   "source": [
    "After fitting and evaluating the RNN model, the results show a significant discrepancy between the training and test accuracies. The training accuracy is impressively high at approximately 93.35%, while the test accuracy is notably lower at around 60.14% indicating possible overfitting of the training data.\n",
    "\n",
    "The RNN model shows a high degree of accuracy on the training set, which might surpass the performance of the ML models there. However, the true measure of a model's effectiveness is its performance on unseen data (test set), where the RNN model seems to underperform. The ML models might not have reached such high training accuracy but could potentially have better generalization, depending on their test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39331e4-44b9-495d-af65-9eebba5daa22",
   "metadata": {},
   "source": [
    "# Save Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a86c294-afa1-41f4-becf-dd0617894c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/nlp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/nlp_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/label_encoder.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the models\n",
    "joblib.dump(pipeline_lr, 'models/ml_model.joblib')\n",
    "model.save('models/nlp_model', save_format='tf')\n",
    "\n",
    "joblib.dump((X_train, y_train), 'data/training_data.joblib')\n",
    "joblib.dump((X_test, y_test), 'data/test_data.joblib')\n",
    "joblib.dump(label_encoder, 'data/label_encoder.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
